#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS:
#+LATEX_HEADER_EXTRA:
#+DESCRIPTION: But it's slow yo
#+KEYWORDS: algorithms graph theory
#+SUBTITLE: What am I looking at?
#+LATEX_COMPILER: pdflatex
#+TITLE: Graph Theory /lite/
#+DATE: <2019-03-06>
#+AUTHOR: Daiwei Chen
#+EMAIL: <redacted>
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 26.1 (Org mode 9.1.14)


* Graph Theory /lite/
  When you would like to model problems with "complex" relationships.
  - Flights :: Catching flights and changing planes.
  - Internet Routing :: The internet is a giant graph. Figuring out the number of hops and which hops to take in order to get to your final destination.
  - Circuit Boards :: Making sure connections are efficient.
  \\
  Basically, things that are connected to each other. A Graph Consists of a set of *vertices* and *nodes* that are /connected/ by _edges_.\\
  Tools: Python - Networkx, c/c++ - nauty.
  Assumptions:\\
  - No Self Loops
  - Edges are Unique

** Paths
   - Path :: List of vertices $l$ such that $(l[i], l[i+1]) \epsilon E$.\\
             On each small step of a path, the 2 nodes much have an edge between them.
   - Simple Path ::  Path without repeated vertices.
   - Cycle :: A (mostly) simple path but the $1^{st}$ and last vertices are the same. Only the beginning and end are repeated.
   - Path Length :: The number of edges in a path.

** Graphs
   - Acyclic Graph :: A graph without *ANY* cycles.
   - Connected Graph :: A graph in which for some a there is an a path from every vertex to every vertex.
   - Tree :: Connected acyclic graph.
     - $|v| -1$ edges.

** Subgraphs
   - Subgraph :: Only contains verticies and edges of the original graph. Edges must have 2 end-points.
   - Spanning Tree :: A subgraph of G that contains all nodes in G and is a tree.
* Keeping Track of Graphs
  These 2 are not the only two styles of graph representations. There are many, many more and more specialized representations for the correct use case.
** Adjacency List
   Just a list, for example:
   | A | -> | B, C, D |
   | B | -> | A, C, E |
   | C | -> | A, B    |
   | D | -> | A, E    |
   | E | -> | B, D    |

** Adjacency Matrix
   Shows if one node is connected to another.
   |   | A | B | C | D | E |
   | A | 0 | 1 | 1 | 1 | 0 |
   | B | 1 | 0 | 1 | 0 | 1 |
   | C | 1 | 1 | 0 | 0 | 0 |
   | D | 1 | 0 | 0 | 0 | 1 |
   | E | 0 | 1 | 0 | 1 | 0 |

* Weighted Graphs
  Just a graph, but the edges has been assigned a value. For example, on a switch, different physical connections could have a weight of how much bandwidth each one gets?

* Minimal Spanning Tree
  You want to find the spanning tree where the total weight is the smallest.

* Prim's Algorithm
  A minimal spanning tree algorithm.
  #+BEGIN_SRC python
    def prims(V:set, E:set):
        tree_vertex_set = {V[random(len(V))]} # The vertex starts with ANY vert we want to start with.
        tree_edge_set = {}

        for i=1..len(V)-1:
            # This very much depends on the way you're storing your edges
            find the minimal edge $e_m$ = ($u_m$, $V_m$) such that $u_m \epsilon$ tree_vertex_set and $V_m !\epsilon$ tree_vertex_set
            tree_edge_set.add($e_m)
            tree_vertex_set.add($V_m)

        return tree_edge_set
  #+END_SRC

  The way that this algorithm works, is that on each run of every vertex, you always find the minimum edge from the starting point, and move on to the next one. Then you do the same until you run out of verticies.
  \\
  Let's look at the complexity for prim's algorithm. It's fairly hard to say what the possible complexity for prim's algorithm is looking like because the finding the minimal edge depending on your algorithm for that and how the data is represented.\\
  Some examples:\\
  - Prim's (Adjacency Matrix) :: $O(n^2)$
  - Prim's (List + Binary Heap) :: $O(e \log n)$
  - Prim's (List + Fibonacci Heap) :: $O(e + n \log n)$

* Kruskal's Algorithm
  It is going to put each vertex into its own set. Then, sort the edges on increasing weight. You start from the lowest weight, and if two vertecies are in different sets, then you combine the sets, and accept that edge. Keep combining as long as your edges are not in the same set.

  #+BEGIN_SRC python
    def kruskals(V: set, E: set):
        construct |V| sets, each with a unique vertex
        sort edges by increasing weight
        tree_edges = {}
        for e=(u,v) in sorted edges:
            if u & v are in different sets:
                combine the sets
                tree_edges.add(e)
            if len(tree_edges) == V-1:
                return tree_edges
  #+END_SRC

  What is the big O on this alogrithm? It is $O(e \log e)$.

* Shortest Path
  Given a weighted directed graph G. Find the shortest path from a source vertex s to a sink vertex t.
  Notes:
  - Negative weights edges are allowed
  - Cycles with negative weights are NOT
  - We will not have cycles with positive weights

 #+BEGIN_SRC python
   def initSSSP(G, s):
       for v in G:
           v.pi = None # the prediciser
           v.d = Inf # best guess on distance

   def relax(u, v):
       if v.d > u.d + weight(u,v):
           v.d = u.d + weight(u,v)
           v.pi = u

   def bellman_ford(G, s):
       initSSSP(G, s)
       for i in range(x): # x runs ____ times Usually, x = len(V)
           for e = (u,v) in G: # for each edge, relax the edge.
               relax(u,v)
       # Detect a negative cycle
       for e = (u,v) in G:
           if v.d > u.d + weight(u,v): # If you can still relax after relaxing, then panic, You've relaxed too much
               return false
       return true
 #+END_SRC

 | u | pi   |  d |
 | S | null |  0 |
 | A | S    |  3 |
 | B | A    | -1 |
 | C | D    | -4 |
 | D | F    | -1 |
 | E | S    |  2 |
 | F | E    |  5 |
 | T | B    |  6 |

 Each time you go through the loop, you'll go at the very least, by one vertex. Note: You go through the table multiple times as to keep every single value within the table updated. In later iterations of the loop, there could be changes in paths without a change in where one vertex comes from vs another. Depending on the graph, it could take up to len(V). Which is why you must check for negative cycles. However, if you've gone through the graph and there're no changes in the table, then you're done relaxing. The order that you check the edges doesn't matter too much.
 Complexity-wise, this is slower than Dyxstra's algorithm, however, dyxtra does not always work on graphs with negatively weighted graphs.

* Graph Traversal / Search
  - Depth First Search (DFS)
  - Breadth First Search (BFS)
** Depth First Search
   Go down, then move to the side.
   #+BEGIN_SRC python
     def dfs(g: Graph, s: vertex):
         visited = set()
         toVisit = stack()
         toVisit.push(s)
         while toVisit is not empty:
             v = toVisit.pop()
             if v not in visited:
                 visited.add(v)
                 for w in v.neighbors:
                     toVisit.push(w)
                 print(v)

     def rdfs(g, s):
         if s not in visited:
             print(s)
             visited.add(s)
             for w in s.neighbors:
                 rdfs(g, w)
   #+END_SRC

** Breadth First Search
   Search down, layer by layer. Horizontally.
